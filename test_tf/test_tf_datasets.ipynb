{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 创建数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.data.Dataset.from_tensors\n",
    "\n",
    "tf.data.Dataset.from_tensor_slices\n",
    "\n",
    "区别是一个是一个数据， 另一个是打散后多个数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensors([1, 2, 3, 4, 5])\n",
    "for elem in dataset:\n",
    "    print(elem.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5])\n",
    "for elem in dataset:\n",
    "    print(elem.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 读取数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.data.TextLineDataset() 从文本中读取\n",
    "\n",
    "tf.data.FixedLengthRecordDataset() 从二进制文件中读取\n",
    "\n",
    "tf.data.TFRecordDataset() 从TF格式记录里面读取\n",
    "\n",
    "其他方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 batch操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch的入参batch_size表示一个batch的大小，也就是每多少个一个batch。这样不会一下全部加载。加载的batch个数用take控制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[10 11 12 13 14 15 16 17 18 19]\n",
      "[20 21 22 23 24 25 26 27 28 29]\n",
      "[30 31 32 33 34 35 36 37 38 39]\n",
      "[40 41 42 43 44 45 46 47 48 49]\n",
      "[50 51 52 53 54 55 56 57 58 59]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(100)\n",
    "batched_dataset = dataset.batch(10)\n",
    "for one_batch in batched_dataset.take(6):\n",
    "    print(one_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 zip操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看做是data和label的整合。整合的方式是一个data对应一个label。\n",
    "\n",
    "每个data和label一一对应，比如第一个(data=[0,1,2,3,4], label=0)，再如第二个(data=[1,2,3,4,5], label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0, 1, 2, 3, 4], dtype=int32), 0]\n",
      "[array([1, 2, 3, 4, 5], dtype=int32), 1]\n",
      "[array([2, 3, 4, 5, 6], dtype=int32), 2]\n",
      "[array([3, 4, 5, 6, 7], dtype=int32), 3]\n",
      "[array([4, 5, 6, 7, 8], dtype=int32), 4]\n",
      "[array([5, 6, 7, 8, 9], dtype=int32), 5]\n",
      "[array([ 6,  7,  8,  9, 10], dtype=int32), 6]\n",
      "[array([ 7,  8,  9, 10, 11], dtype=int32), 7]\n",
      "[array([ 8,  9, 10, 11, 12], dtype=int32), 8]\n",
      "[array([ 9, 10, 11, 12, 13], dtype=int32), 9]\n",
      "[array([10, 11, 12, 13, 14], dtype=int32), 10]\n",
      "[array([11, 12, 13, 14, 15], dtype=int32), 11]\n",
      "[array([12, 13, 14, 15, 16], dtype=int32), 12]\n",
      "[array([13, 14, 15, 16, 17], dtype=int32), 13]\n",
      "[array([14, 15, 16, 17, 18], dtype=int32), 14]\n",
      "[array([15, 16, 17, 18, 19], dtype=int32), 15]\n"
     ]
    }
   ],
   "source": [
    "m = 16\n",
    "data = tf.data.Dataset.from_tensor_slices([list(range(i, i+5)) for i in range(m)])\n",
    "labels = tf.data.Dataset.from_tensor_slices([i for i in range(m)])\n",
    "dataset = tf.data.Dataset.zip((data, labels))\n",
    "for elem in dataset:\n",
    "    print([e.numpy() for e in elem])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 zip的batch操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0, 1, 2],\n",
      "       [1, 2, 3],\n",
      "       [2, 3, 4]], dtype=int32), array([0, 1, 2], dtype=int32)]\n",
      "[array([[3, 4, 5],\n",
      "       [4, 5, 6],\n",
      "       [5, 6, 7]], dtype=int32), array([3, 4, 5], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "m = 16\n",
    "data = tf.data.Dataset.from_tensor_slices([list(range(i, i+3)) for i in range(m)])\n",
    "labels = tf.data.Dataset.from_tensor_slices([i for i in range(m)])\n",
    "dataset = tf.data.Dataset.zip((data, labels))\n",
    "batched_dataset = dataset.batch(3)\n",
    "for elem in batched_dataset.take(2):\n",
    "    print([e.numpy() for e in elem])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 shuffle操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "3 5 2 0 8 6 4 9 11 12 10 14 1 7 17 18 16 13 19 15 "
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(20)\n",
    "for elem in dataset:\n",
    "    print(elem.numpy(), end=' ')\n",
    "    \n",
    "print()\n",
    "shuffled_dataset = dataset.shuffle(6)\n",
    "for elem in shuffled_dataset:\n",
    "    print(elem.numpy(), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 常用的数据集 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras.datasets\n",
    "\n",
    "tf.keras.datasets.xx.load_data()就可以将xx数据集加载\n",
    "\n",
    "常用的数据集有\n",
    "\n",
    "boston_housing、cifar10、cifar100、fashion_mnist、imdb、mnist、reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
