{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "np_data = np.arange(6).reshape((2, 3))\n",
    "torch_data = torch.tensor(np_data) # 张量\n",
    "tensor2array = torch_data.numpy()\n",
    "\n",
    "print(\n",
    "    '\\nnumpy array:\\n', np_data,\n",
    "    '\\ntorch tensor\\n', torch_data,\n",
    "    '\\ntensor to array\\n', tensor2array\n",
    ")\n",
    "\n",
    "# float 类型\n",
    "# torch.float16\n",
    "# torch.float32\n",
    "# torch.float64\n",
    "\n",
    "# int 类型\n",
    "# torch.uint8\n",
    "# torch.int8\n",
    "# torch.int16\n",
    "# torch.int32\n",
    "# torch.int64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nnumpy.abs:\n [[1 2]\n [1 2]] \ntorch.abs:\n tensor([[1, 2],\n        [1, 2]]) \nnumpy.sin:\n [0.         0.70710678 1.        ] \ntorch.sin:\n tensor([0.0000, 0.7071, 1.0000], dtype=torch.float64) \nnumpy.mean\n 2.0 \ntorch.mean\n tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "np_data = np.array([[1, 2], [1, 2]])\n",
    "torch_data = torch.tensor(np_data)\n",
    "\n",
    "np_t = np.array([0, np.pi / 4., np.pi / 2.])\n",
    "torch_t = torch.tensor(np_t)\n",
    "\n",
    "# 平均值\n",
    "np_x = np.arange(5)\n",
    "torch_x = torch.FloatTensor([i for i in range(5)])\n",
    "# torch.mean 只能计算float的平均值，不能计算int的平均值，所有必须用FloatTensor\n",
    "\n",
    "print(\n",
    "    '\\nnumpy.abs:\\n', np.abs(np_data),\n",
    "    '\\ntorch.abs:\\n', torch.abs(torch_data),\n",
    "    '\\nnumpy.sin:\\n', np.sin(np_t),\n",
    "    '\\ntorch.sin:\\n', torch.sin(torch_t),\n",
    "    '\\nnumpy.mean\\n', np.mean(np_x),\n",
    "    '\\ntorch.mean\\n', torch.mean(torch_x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3]\n [3 7]]\n[[1 2]\n [0 4]]\ntensor([[1., 3.],\n        [3., 7.]])\ntensor([[1., 2.],\n        [0., 4.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# numpy矩阵相乘\n",
    "na = np.array([[1, 2], [3, 4]])\n",
    "nb = np.array([[1, 1], [0, 1]])\n",
    "nc = na @ nb  # nc = np.matmul(na, nb)\n",
    "nd = na * nb\n",
    "print(nc, nd, sep='\\n')\n",
    "\n",
    "# torch矩阵相乘\n",
    "ta = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "tb = torch.FloatTensor([[1, 1], [0, 1]])\n",
    "tc = torch.mm(ta, tb)\n",
    "td = ta * tb\n",
    "print(tc, td, sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n        [3., 4.]])\ntensor([[1., 2.],\n        [3., 4.]], requires_grad=True)\ntensor(7.5000)\ntensor(7.5000, grad_fn=<MeanBackward0>)\ntensor([[0.5000, 1.0000],\n        [1.5000, 2.0000]])\ntensor([[1., 2.],\n        [3., 4.]], requires_grad=True)\ntensor([[1., 2.],\n        [3., 4.]])\n[[1. 2.]\n [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# 变量\n",
    "tensor = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "variable = Variable(tensor, requires_grad=True)\n",
    "print(tensor)\n",
    "print(variable)\n",
    "t_mean = torch.mean(tensor * tensor)\n",
    "v_mean = torch.mean(variable * variable)\n",
    "print(t_mean)\n",
    "print(v_mean)\n",
    "\n",
    "# 反向传播求导数\n",
    "v_mean.backward()\n",
    "print(variable.grad)\n",
    "\n",
    "print(variable)  # Variable形式\n",
    "print(variable.data)  # tensor形式\n",
    "print(variable.data.numpy())  # numpy形式，随后输出结果一般用numpy形式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# 内置数据集\n",
    "# workdir = os.getcwd()\n",
    "# torchvision.datasets.MNIST(\n",
    "#     root=workdir, \n",
    "#     train=True,\n",
    "#     transform=None, # 对data是否进行修改，比如Normalization\n",
    "#     target_transform=None, # 对label是否进行修改，比如1,2,...,9变成向量形式\n",
    "#     download=False # 是否下载\n",
    "# )\n",
    "\n",
    "root = os.path.dirname(os.getcwd())\n",
    "# d = torchvision.datasets.FashionMNIST(root, download=True)\n",
    "# print(root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# 自定义数据集\n",
    "# 继承 torch.utils.data.Dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        必须实现这个方法，给len()函数用\n",
    "        :return: \n",
    "        \"\"\"\n",
    "        pass\n",
    "    def __getitem__(self, item):\n",
    "        \"\"\"\n",
    "        必须实现这个方法，给datasets[i]下标索引用\n",
    "        可以for迭代\n",
    "        :param item: \n",
    "        :return: \n",
    "        \"\"\"\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "\n",
    "# 另一种高级的迭代数据集的方式\n",
    "# torch.utils.data.DataLoader\n",
    "# num_workers 多线程\n",
    "# dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
