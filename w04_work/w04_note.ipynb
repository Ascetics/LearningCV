{
 "cells": [
  {
   "cell_type": "heading",
   "metadata": {
    "collapsed": true
   },
   "level": 1,
   "source": [
    "学习分为Model、Data、Training、Inference、Deployment；现在进入Data部分；竞赛第一名https://github.com/gujingxiao/Lane-Segmentation-Solution-For-BaiduAI-Autonomous-Driving-Competition"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "对于数据集：\n",
    "我们使用Gray_Label里面的灰度标签；Labels_Fixed是RGB标签，只是灰度和RGB的一个映射。\n",
    "我们使用Road02-04里面的数据，数据里面的lable不要使用，那些label是无效的。\n",
    "\n",
    "数据增强肯定可以增加准确率，但是在项目开始时，不建议使用。应先建立baseline，尽快是模型能够跑起来，再想办法提高精度。"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "注意观察数据。观察数据的分布、数据不平衡问题、异常、错误等。用数据清洗的办法解决。\n",
    "\n",
    "如果二分类类别不平衡，A分类99%，B分类1%，那么模型学不到东西。因为给一个图片就标记A就可以获得99%的正确率。"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "语义分割常见的数据集：PASCAL VOC 2012、cityscapes；我们Lane Segmentation的数据集是阿波罗数据集的一部分。阿波罗数据集的论文地址https://arxiv.org/abs/1803.06184，论文题目The ApolloScape Open Dataset for Autonomous Driving and its Application"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "语义分割的Label比较特殊，是和原图大小一样的图。或者label比原图要小，因为只对其中一部分感兴趣。要有自己的工具，可以参考COCO API，地址https://github.com/cocodataset/cocoapi"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "数据集的安装pip install tensorflow-dataset"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "data和label对应可以用文件名，文件名是时间戳命名的。观察数据集，每个图片的大小H*W=1710*3384。图片的大小很大，不能全部加载，会把内存吃掉。迭代前resize。"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "数据集的格式，采用CSV格式，可以用pandas库来处理。写程序生成csv文件，用这个文件去索引image和label。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Pandas库\n",
    "# 生成csv文件\n",
    "save = pd.DataFrame({'image':image_list, 'label':label_list})\n",
    "save_shuffle = shuffle(save)\n",
    "save_shuffle.to_csv('../data_list/train.csv', index=False)\n",
    "\n",
    "# 读取csv文件\n",
    "data_dir = './data_list/train.csv'\n",
    "train_list = pd.read_csv(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "组织项目的目录\n",
    "d:data_list 放csv文件的目录，也就是data和label列表\n",
    "d:models 放模型的目录\n",
    "d:utils 放工具类、工具函数的目录\n",
    "README.md\n",
    "xxx.py\n",
    ".......\n",
    "train.py 做训练\n",
    "val_inference.py 做推断，推断是需要单独部署的"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "推断的方式，也就是predict的方式，可以用模型融合。baseline里面的模型融合就是三个模型的推断做平均值，用平均值作为推断。"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "由于GPU的限制，在服务器上建立训练用的张量N*C*H*W里面的N，mini-batch也就是N一般选择2。\n",
    "注意维度的转换， NHWC维度转换为NCHW维度。\n",
    "NHWC（CPU）\n",
    "NCHW（GPU）"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "训练的时候，用trainId，trainId是0-8连续的9个分类，方便做成one-hot向量label。\n",
    "提交结果时，将推断映射到trainId对应的任意一个id就行。\n",
    "注意：ignoreInEval列，ignoreInEval==True表示忽略，表示这个数据集里面就没有这个分类，因此不必要关注。直接将这类trainId变成背景类void。\n",
    "注意：trainId==4的这个类别，ignoreInEval都是True，说明整个这个类别在数据集里面都没有。那么，就把这个类别忽略掉，后面的递进补上，5变成4，6变成5……8变成7。这样最终，实际只有8个分类。"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "完成make_list和process_label功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
